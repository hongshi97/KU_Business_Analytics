# SVM

## ëª©ì°¨

1. [ì´ë¡ ](#ì´ë¡ )
   1. [Margin](#Margin)
   2. [Optimization](#Optimization-ë¬¸ì œ)
   3. [Soft Margin SVM](#Soft-Margin-SVM)
   4. [Nonlinear&Kernel](#Nonlinear-&-Kernel)
2. [ì½”ë”© ì‹¤ìŠµ](#ì½”ë”©-ì‹¤ìŠµ)
   1. [ì‹¤í—˜ ì£¼ì œ](#ì‹¤í—˜-ì£¼ì œ)
   2. [Main Experiment - Support Vector Classifier](#Main-Experiment---Support-Vector-Classifier)
      1. [SVC ê²°ê³¼ í•´ì„](#SVC-ê²°ê³¼-í•´ì„)
   3. [Additional Experiment - Support Vector Regressor](#Additional-Experiment---Support-Vector-Regressor)
      1. [SVR ê²°ê³¼ í•´ì„](#SVR-ê²°ê³¼-í•´ì„)

---
># **ì´ë¡ **

**S**uppor **V**ector **M**achine

Keywords: Margin, Hyperplane, Support Vector
 

ğŸ“¢ ìš”ì•½: Support Vector Machineì€ Vector Space ìƒì—ì„œ Vectorë“¤ì„ ê°€ì¥ ì˜ ë¶„ë¥˜í•˜ëŠ” Hyperplaneì„ ìˆ˜ë¦½í•˜ëŠ” ê²ƒì„ ëª©í‘œë¡œ í•œë‹¤.

- Background
    - Hyperplane(ì´ˆí‰ë©´): a subspace of one dimension less than its ambient space
      
      
    <p align="center">
    <image src=https://user-images.githubusercontent.com/56019094/199520467-88e4f48d-11e1-42a2-868b-0ca4ddcf7b56.png
    height="300"/>  
    </p>
    ì´ë¯¸ì§€ ì¶œì²˜: Support Vector Machines without tears
        
    - nì°¨ì›ì˜ ê³µê°„ì—ì„œ Hyperplaneì€ n-1ì°¨ì›ì˜ subspaceë¥¼ ì˜ë¯¸
        - 2ì°¨ì›ì˜ ê²½ìš° Hyperplaneì€ 1ì°¨ì›(ì§ì„ )
        - 3ì°¨ì›ì˜ ê²½ìš° Hyperplaneì€ 2ì°¨ì›(í‰ë©´)  
        â‡’ SVMì—ì„œ Hyperplaneì€ ì–´ë–¤ Vector Space ìƒì— ì¡´ì¬í•˜ëŠ” Vectorë“¤ì„ ë¶„ë¥˜í•˜ëŠ” Decision Boundary(ê²°ì • ê²½ê³„)ì— í•´ë‹¹
        

>## Margin

>>### â€œê°€ì¥ ì˜ ë¶„ë¥˜í•˜ëŠ”â€ì˜ ê¸°ì¤€ì´ ë¬´ì—‡ì¸ê°€?

- SVMì€ Vector Space ìƒì— ìˆëŠ” Vector í˜•íƒœë¡œ í‘œí˜„ëœ ê° Data Pointë“¤ì„ ê°€ì¥ ì˜ ë¶„ë¥˜í•˜ëŠ” Hyperplane(ì´ˆí‰ë©´)ì„ ìˆ˜ë¦½í•˜ëŠ” ê²ƒì„ ëª©í‘œë¡œ í•¨
  

<p align = 'center'>
<image src=https://user-images.githubusercontent.com/56019094/199521480-96c01d5c-4bc4-4f18-8273-b4814f0320b6.png height = '300'></p>
    

>>### Marginì„ ìµœëŒ€í™”í•˜ëŠ” Hyperplaneì„ ì°¾ì

- Marginì´ë€?
  
    : Hyperplaneìœ¼ë¡œë¶€í„° ë“± ê°„ê²©ìœ¼ë¡œ ì–‘ìª½ìœ¼ë¡œ í™•ì¥ì‹œì¼°ì„ ë•Œ Hyperplaneê³¼ ê°€ì¥ ê°€ê¹Œìš´ ê°ì²´(Support Vector)ì™€ì˜ ê±°ë¦¬
    
    <p align = 'center'>
    <image src=https://user-images.githubusercontent.com/56019094/199521778-96a75042-461b-4104-98e3-325bd3c33065.png height = '300'></p>
    
    - ìœ„ì˜ Hyperplane ë„¤ ê°œ ëª¨ë‘ ë‹¤ ë°ì´í„°ë“¤ì„ ì˜ ë¶„ë¥˜í•˜ëŠ”ë° Marginì´ í¬ë©´ ë­ê°€ ì¢‹ì„ê¹Œ?
      
        **Margin ìµœëŒ€í™” â†’ êµ¬ì¡°ì  ìœ„í—˜ ìµœì†Œí™”**
        
        Equation 1)
        
        $$
        h \le min(\lceil {{R^2 \over \triangle^2}}\rceil, D) + 1
        $$
        
        Equation 2)
        
        $$
        R[f] \le R_{emp}[f] + \sqrt{{h{(ln{2n\over h}}+1)-ln({\delta \over 4}) }\over{n}}
        $$
        
        $notation$
        
        $h$: VC Dimension
        
        $R$: ëª¨ë“  Input Vectorë“¤ì„ í¬í•¨í•˜ëŠ” ê°€ì¥ ì‘ì€ êµ¬
        
        $\triangle$: Margin
        
        $D$: Input Spaceì˜ ì°¨ì›(= ë³€ìˆ˜ ê°œìˆ˜)
        
        - Equation 1)ì—ì„œ Dì™€ Rì€ Input Dataê°€ ì£¼ì–´ì§€ë©´ ì •í•´ì§„ ê°’ìœ¼ë¡œ, ë³€í™” ê°€ëŠ¥í•œ ê²ƒì€ $\triangle$ (Margin)
            - $\triangle$(Margin) ì¦ê°€ â†’ $R^2 \over \triangle^2$ ê°ì†Œ â†’  $min(\lceil{R^2 \over \triangle^2}, D\rceil)$ ê°ì†Œ â†’ $h$  (VC Dimension) ê°ì†Œ
              
                â†’ $\sqrt{{h{(ln{2n\over h}}+1)-ln({\delta \over 4}) }\over{n}}$ (Capacity Term) ê°ì†Œ â†’ $R[f]$ (êµ¬ì¡°ì  ìœ„í—˜) ê°ì†Œ
                

>>### Marginì„ ì–´ë–»ê²Œ ê³„ì‚°í•  ê²ƒì¸ê°€?

<p align = 'center'>
<image src=https://user-images.githubusercontent.com/56019094/199521970-0e80400c-3430-4f84-9e91-2f041f01882a.png height = '300'> </p>

Hyperplaneì„ $\boldsymbol{w}^T\boldsymbol{x} + b$

where $\boldsymbol{w} = (w_1,w_2)^T$ ë¼ê³  ê°€ì •

- ë²¡í„° $\boldsymbol{w}$ëŠ” ì´ Hyperplaneê³¼ ìˆ˜ì§ì¸ ë²•ì„  ë²¡í„°
- $\boldsymbol{w}$ì— ëŒ€í•´ ì›ì ê³¼ì˜ ê±°ë¦¬ê°€ $b$ì¸ ì§ì„ ì˜ ë°©ì •ì‹ì€ $\boldsymbol{w}^T\boldsymbol{x} + b = 0$  â‡’ $w_1x_1 + w_2x_2 + b = 0$
- ìœ„ ì§ì„ ì˜ ê¸°ìš¸ê¸°ëŠ” $- {w_1\over w_2}$ì´ê³ , ë²•ì„  ë²¡í„° $\boldsymbol{w}$ì˜ ê¸°ìš¸ê¸°ëŠ” $w_2 \over w_1$ â‡’ ë‘ ì§ì„ ì€ ì§êµ

â‡’ Plus-plane ìœ„ì— ìˆëŠ” ë²¡í„° $\boldsymbol{x}^+$ì™€ Minus-plane ìœ„ì— ìˆëŠ” ë²¡í„° $\boldsymbol{x}^-$ ì‚¬ì´ì˜ ê´€ê³„ë¥¼ ë‹¤ìŒê³¼ ê°™ì´ ì •ì˜ ê°€ëŠ¥
- $\boldsymbol{x}^+ = \boldsymbol{x}^- + \lambda \boldsymbol{w}$
    - ìœ„ ìˆ˜ì‹ì€ $\boldsymbol{x}^-$ë¥¼ $\boldsymbol{w}$ ë°©í–¥ìœ¼ë¡œ $\lambda$ë§Œí¼ í‰í–‰ì´ë™ì‹œí‚¨ë‹¤ëŠ” ì˜ë¯¸
- $\lambda$ëŠ” ê³„ì‚°í•  ìˆ˜ ìˆì„ê¹Œ?
  
    : $\boldsymbol{w}^T\boldsymbol{x}^+ + b = 1$
    
    â†’ $\boldsymbol{w}^T(\boldsymbol{x}^- + \lambda\boldsymbol{w}) + b = 1$
    
    â†’ $\boldsymbol{w}^T\boldsymbol{x}^- + b + \lambda \boldsymbol{w}^T\boldsymbol{w} = 1$          where, $(\boldsymbol{w}^T\boldsymbol{x}^- + b = 1)$
    
    â†’  $-1 + \lambda\boldsymbol{w}^T\boldsymbol{w} = 1$
    
    â‡’ $\lambda = {2 \over \boldsymbol{w}^T\boldsymbol{w}}$ 
    

í•œí¸, Marginì€ Plus-planeê³¼ Minus-plane ì‚¬ì´ì˜ ê±°ë¦¬ $distance(\boldsymbol{x}^+, \boldsymbol{x}^-)$ì™€ ê°™ìŒ

$Margin = distance(\boldsymbol{x}^+, \boldsymbol{x}^-)$

$= ||\boldsymbol{x}^+ - \boldsymbol{x}^-||_2$

$= ||\boldsymbol{x}^- + \lambda\boldsymbol{w}- \boldsymbol{x}^-||_2$ , where, $\boldsymbol{x}^+ = \boldsymbol{x}^- + \lambda \boldsymbol{w}$

$= ||\lambda\boldsymbol{w}||_2$

$= \lambda \sqrt{\boldsymbol{w}^T\boldsymbol{w}}$

 $= {2 \over \boldsymbol{w}^T\boldsymbol{w}}\sqrt{\boldsymbol{w}^T\boldsymbol{w}}$ , where, $\lambda = {2 \over \boldsymbol{w}^T\boldsymbol{w}}$

$= {2 \over \sqrt{\boldsymbol{w}^T\boldsymbol{w}}}$

$= {2 \over ||w||_2}$

>## Optimization ë¬¸ì œ

**Remind!** SVMì˜ ëª©ì ì€ **Margin**ì„ **ìµœëŒ€**ë¡œ í•˜ëŠ” Hyperplaneì„ ì°¾ëŠ” ê²ƒ

>>### ëª©ì  í•¨ìˆ˜ ë° ì œì•½ ì¡°ê±´

- Marginì„ ìµœëŒ€í™”:  $max$  ${2 \over ||w||^2}$    --ì—­ìˆ˜->     $min$   ${1 \over 2}||w||^2$
  
    $min$   ${1 \over 2}||w||^2$
    
    $s.t.$   $y_i(\boldsymbol{w}^T\boldsymbol{x}_i + b) \ge 1$   , $\forall i$
    
    <p align = 'center'>
    <img src = https://user-images.githubusercontent.com/56019094/199522537-dcbdf18f-d3d0-4e16-8130-23c6f1a73f14.png height = '300'></p>
    
    - Let $\boldsymbol{x}_i$ = íŒŒë€ìƒ‰ Data Object, $\boldsymbol{x}_j$ = ë¹¨ê°„ìƒ‰ Data Object
        - $\boldsymbol{w}\boldsymbol{x}_i \ge 1$      $(y_i = +1)$  â†’   $y_i(\boldsymbol{w} \cdot \boldsymbol{x}_i + b) \ge +1$
        - $\boldsymbol{w}\boldsymbol{x}_j \le -1$  $(y_j = -1)$ â†’   $y_j(\boldsymbol{w} \cdot \boldsymbol{x}_j + b ) \ge +1$
        
        â‡’ $y$ = $\pm 1$ì¸ ê²½ìš° ëª¨ë‘, ìˆ˜ì‹ì´ ë™ì¼í•˜ê²Œ ìœ„ ì œì•½ ì¡°ê±´ê³¼ ê°™ì´ ì •ë¦¬ë¨ 
            (Plus. SVMì—ì„œ Class Labelì„ 0/1ì´ ì•„ë‹Œ +1/-1ë¡œ ì„¤ì •í•œ ì´ìœ ) 
        
    

>>### ë¼ê·¸ë‘ì§€ì•ˆ ë¬¸ì œë¡œ ë³€í™˜

- ê¸°ì¡´ ëª©ì  í•¨ìˆ˜ ë° ì œì•½ ì¡°ê±´
  
    $min \quad {1 \over 2}||w||^2$
    
    $s.t.$   $y_i(\boldsymbol{w}^T\boldsymbol{x}_i + b) \ge 1$   , $\forall i$
    
    â‡’ ìœ„ ì‹ì—ì„œ $y_i, \boldsymbol{x}_i$ëŠ” ì£¼ì–´ì§„ ê°’ì´ê³ , $\boldsymbol{w}$ì™€ $b$ê°€ ë¯¸ì§€ìˆ˜ ì¦‰, ìµœì í™” ëŒ€ìƒ
    
- ë¼ê·¸ë‘ì§€ì•ˆ ë¬¸ì œ
  
    ${\min\quad{L_{p}(\boldsymbol{w},b,{\alpha}_{i})}}=\frac{1}{2}{\left\|\boldsymbol{w}\right\|}^{2}-\sum _{i=1}^{N}{{\alpha}_{i}({y}_{i}({\boldsymbol{w}}^{T}{\boldsymbol{x}}_{i}+b)-1)}$
    $s.t.$   $\alpha_i \ge 0$

>>### ìŒëŒ€(Dual) ë¬¸ì œë¡œ ë³€í™˜

- KKT ì¡°ê±´
  
    ${\partial L_p \over \partial \boldsymbol{w}} = 0$   â‡’  $\boldsymbol{w} = \sum_{i=1}^N {\alpha_iy_i\boldsymbol{x}_i}$
    
    ${\partial L_p \over  \partial b} = 0$   â‡’    $\sum_{i=1}^N {\alpha_iy_i} = 0$
    
- ì›ë¬¸ì œ
  
    ${\min\quad{L_{p}(\boldsymbol{w},b,{\alpha}_{i})}} =\frac{1}{2}{\left\|\boldsymbol{w}\right\|}^{2}-\sum _{i=1}^{N}{{\alpha}_{i}({y}_{i}({\boldsymbol{w}}^{T}{\boldsymbol{x}}_{i}+b)-1)}$
    $s.t.$   $\alpha_i \ge 0$ 

- ìŒëŒ€(Dual) ë¬¸ì œ
  
    $\max \quad { { L }_{ D }({ \alpha  }_{ i }) } =\sum _{ i=1 }^{ N }{ { \alpha  }_{ i } } -\frac { 1 }{ 2 } \sum _{ i=1 }^{ N }{ \sum _{ j=1 }^{ N }{ { \alpha  }_{ i }{ { \alpha  }_{ j }y }_{ i }{ y }_{ j }{ \boldsymbol{x} }_{ i }^{ T }{ \boldsymbol{x} }_{ j } }  }$
    
    $s.t.$    $\sum _{ i=1 }^{ N }{ { \alpha  }_{ i }{ y }_{ i } } =0, \quad
    { \alpha  }_{ i }\ge 0$
    
    
    
    - ìœ„ ìŒëŒ€ ë¬¸ì œì—ì„œ $\boldsymbol{x}$ì™€ $y$ëŠ” ë°ì´í„°ë¡œë¶€í„° ì£¼ì–´ì§„ ê°’ì´ê³  $\alpha$ë§Œ ë¯¸ì§€ìˆ˜
    - ì´ë•Œ, KKT ì¡°ê±´ì— ë”°ë¼ $\alpha_i(y_i(\boldsymbol{w}^T\boldsymbol{x}_i + b) -1) = 0$ ì´ë¼ëŠ” ìˆ˜ì‹ì´ ì„±ë¦½í•¨
      
        â‡’ $\alpha_i = 0, (y_i(\boldsymbol{w}^T\boldsymbol{x}_i + b) -1) \ne 0$ ì´ê±°ë‚˜ $\alpha_i \ne 0, (y_i(\boldsymbol{w}^T\boldsymbol{x}_i + b) -1) = 0$
        
        - $\alpha_i \ne 0, (y_i(\boldsymbol{w}^T\boldsymbol{x}_i + b) -1) = 0$ì¸ ê²½ìš°,
          
            $(y_i(\boldsymbol{w}^T\boldsymbol{x}_i + b) -1) = 0$   â†’   $y_i(\boldsymbol{w}^T\boldsymbol{x}_i + b) = 1$ì´ë¼ëŠ” ê²ƒì€ 
            
            $\boldsymbol{x}_i$ê°€ Plus-planeê³¼ Minus-plane ìƒì— ìœ„ì¹˜í•œë‹¤ëŠ” ê²ƒì„ ì˜ë¯¸
            â†’ ì´ $\boldsymbol{x}_i$ ( = Support Vector)ì— ëŒ€í•´ì„œë§Œ $\alpha_i$ëŠ” 0ë³´ë‹¤ í° ê°’ì„ ê°€ì§€ê²Œ ë¨.
            
            <p align = 'left'><img src = https://user-images.githubusercontent.com/56019094/199523250-335b3594-beef-4cba-8598-fe7931fdf682.png height = '300'></p>
            ì´ë¯¸ì§€ ì¶œì²˜: [https://techblog-history-younghunjo1.tistory.com/m/78]
            

>>### ìµœì¢… Hyperplane êµ¬í•˜ê¸°

- SVMì—ì„œ ì°¾ê³ ì í•˜ëŠ” ê²ƒì€ Marginì´ ìµœëŒ€í™”ëœ Hyperplane $\boldsymbol{w}^T\boldsymbol{x} + b$
  
    â†’ $\boldsymbol{w}$ì™€ $b$ë¥¼ ì°¾ìœ¼ë©´ Hyperplane êµ¬í•  ìˆ˜ ìˆìŒ
    
- ì´ì „ ë‹¨ê³„ì—ì„œ ì•„ë˜ì™€ ê°™ì€ ìˆ˜ì‹ì„ ì–»ì—ˆìŒ
  
    $\boldsymbol{w} = \sum_{i=1}^N {\alpha_iy_i\boldsymbol{x}_i}$
    
    - $\boldsymbol{x}_i, y_i$ëŠ” ì£¼ì–´ì§„ ë°ì´í„°ë¡œë¶€í„° ì•Œì•„ë‚¼ ìˆ˜ ìˆëŠ” ê°’ì´ë¯€ë¡œ ë‹¨ í•˜ë‚˜ë¿ì¸ ë¯¸ì§€ìˆ˜ì¸ $\alpha$ë¥¼ ì•Œë©´ $\boldsymbol{w}$ë¥¼ ì°¾ì•„ë‚¼ ìˆ˜ ìˆìŒ
    - $\boldsymbol{w}$ë¥¼ êµ¬í•œ ë’¤, $(y_i(\boldsymbol{w}^T\boldsymbol{x}_i + b) -1) = 0$ì„ í†µí•´ $b$ë¥¼ êµ¬í•  ìˆ˜ ìˆìŒ
- ìƒˆë¡œìš´ Instance$(\boldsymbol{x}_{new}$ê°€ ë“¤ì–´ì˜¤ë©´) $y_i(\boldsymbol{w}^T\boldsymbol{x}_{new} + b) -1$ì— ë„£ì–´ì„œ ê·¸ ê°’ì´ 0ë³´ë‹¤ í¬ë©´ Class Labelì„ +1ë¡œ, ê°’ì´ 0ë³´ë‹¤ ì‘ìœ¼ë©´ Class Labelì„ -1ë¡œ ì˜ˆì¸¡í•¨

>## Soft Margin SVM

- ì´ì „ê¹Œì§€ ì„¤ëª…í•œ SVMì€ Hyperplaneê³¼ Support Vectors ì‚¬ì´ì— Instanceê°€ ì¡´ì¬í•˜ì§€ ì•Šë„ë¡ í•˜ëŠ” Hard Margin SVMì´ì—ˆìŒ
- Soft Margin SVMì€ Hyperplaneê³¼ Support Vectors ì‚¬ì´ì— ì–´ëŠì •ë„ Instanceê°€ ì¡´ì¬í•˜ëŠ” ê²ƒì„ í—ˆìš©

>>### ëª©ì  í•¨ìˆ˜ ë° ì œì•½ ì¡°ê±´

$min \quad {1 \over 2}||\boldsymbol{w}||^2 +C\sum_{i=1}^N \xi_i$

$s.t. \quad y_i(\boldsymbol{w}^T\boldsymbol{x}_i + b) \ge 1-\xi_i, \quad \xi_i \ge0, \forall i$

<p align = 'left'><img src = https://user-images.githubusercontent.com/56019094/199524039-91704ab9-95e5-40be-a78e-83a4f7151e5a.png height = '250'></p>

$notation$

$C$: Penaltyì˜ ì •ë„ë¥¼ ì¡°ì ˆí•˜ëŠ” Hyperparameter

$\xi$: Penalty

â‡’ ë¯¸ì§€ìˆ˜: $\boldsymbol{w}, b, \xi$

>>### ë¼ê·¸ë‘ì§€ì•ˆ ë¬¸ì œë¡œ ë³€í™˜

$ min \quad { L_{p}(\boldsymbol{w},b,{ \alpha  }_{ i }) }   =\frac { 1 }{ 2 } { \left\| \boldsymbol{w} \right\|  }^{ 2 } + {C\sum_{i=1}^N\xi_i}-\sum _{ i=1 }^{ N }{ { \alpha  }_{ i }({ y }_{ i }({ \boldsymbol{w} }^{ T }{ \boldsymbol{x} }_{ i }+b)-1 + \xi_i) } - \sum_{i=1}^N\mu_i\xi_i$

$s.t.\quad\alpha_i \ge 0$

>>### ìŒëŒ€(Dual) ë¬¸ì œë¡œ ë³€í™˜

- ì›ë¬¸ì œ

$\min \quad{ L_{p}(\boldsymbol{w},b,{ \alpha  }_{ i }) }   =\frac { 1 }{ 2 } { \left\| \boldsymbol{w} \right\|  }^{ 2 } + {C\sum_{i=1}^N\xi_i}-\sum _{ i=1 }^{ N }{ { \alpha  }_{ i }({ y }_{ i }({ \boldsymbol{w} }^{ T }{ \boldsymbol{x} }_{ i }+b)-1 + \xi_i) } - \sum_{i=1}^N\mu_i\xi_i$


$s.t.\quad\alpha_i \ge 0$

- KKT ì¡°ê±´
  
    ${\partial L_p \over {\partial \boldsymbol{w}}} = 0 \quad$ â‡’     $\boldsymbol{w} = \sum_{i=1}^n\alpha_iy_i\boldsymbol{x}_i$
    
    ${\partial L_p \over \partial b} = 0\quad$â‡’     $\sum_{i=1}^n\alpha_iy_i = 0$
    
    ${\partial L_p \over \partial \xi_i} = 0\quad$â‡’     $C - \alpha_i - \mu_i = 0$
    

â‡’ $L_D = {1 \over 2}\sum_i\sum_j\alpha_i\alpha_jy_iy_j\boldsymbol{x}_i\cdot\boldsymbol{x}_j + C\sum_i \xi_i -\sum_i\sum_j\alpha_i\alpha_jy_iy_j\boldsymbol{x}_i\cdot\boldsymbol{x}_j - b\sum_i\alpha_iy_i + \sum_i\alpha_i - \sum_i\alpha_i\xi_i - \sum_i\mu_i\xi_i$

â†’ $\sum_i(C-\alpha_i-\mu_i)\xi_i = 0$, $\sum_i\alpha_iy_i = 0$

â†’ $L_D = {1 \over 2}\sum_i\sum_j\alpha_i\alpha_jy_iy_j\boldsymbol{x}_i\cdot\boldsymbol{x}_j -\sum_i\sum_j\alpha_i\alpha_jy_iy_j\boldsymbol{x}_i\cdot\boldsymbol{x}_j + \sum_i\alpha_i$ 

â†’ $L_D = \sum_i\alpha_i  - {1 \over 2}\sum_i\sum_j\alpha_i\alpha_jy_iy_j\boldsymbol{x}_i\cdot\boldsymbol{x}_j$

â‡’ $L_D({\alpha_i}) = \sum_{i=1}^N\alpha_i  - {1 \over 2}\sum_{i=1}^N\sum_{j=1}^N\alpha_i\alpha_jy_iy_j\boldsymbol{x}_i^T\boldsymbol{x}_j$

- ìŒëŒ€ ë¬¸ì œ

$max\quad L_D({\alpha_i}) = \sum_{i=1}^N\alpha_i  - {1 \over 2}\sum_{i=1}^N\sum_{j=1}^N\alpha_i\alpha_jy_iy_j\boldsymbol{x}_i^T\boldsymbol{x}_j$


$s.t.\quad \sum_{i=1}^N \alpha_iy_i = 0, 0 \le \alpha_i \le C$



>>### Plus) $\alpha_i$ ê°’ì— ë”°ë¥¸ Instance ìœ„ì¹˜

KKT ì¡°ê±´ìœ¼ë¡œë¶€í„° $\alpha_i(y_i(\boldsymbol{w}^T\boldsymbol{x} + b)-1+\xi_i) = 0$ ìˆ˜ì‹ì„ ì–»ì„ ìˆ˜ ìˆì—ˆìŒ
- Support Vectorì— ëŒ€í•´ì„œë§Œ $\alpha_i \ne 0$ì´ ì„±ë¦½

ë˜í•œ $C - \alpha_i - \mu_i = 0, \mu_i\xi_i = 0$ì´ë¼ëŠ” ìˆ˜ì‹ì´ ì„±ë¦½í•¨
- **Case 1)** $\alpha_i = 0\quad$â‡’ Support Vectorê°€ ì•„ë‹Œ Instance
- **Case 2)** $0<\alpha_i < C\quad$
  â†’  $\mu_i < C$ì´ë©´ $C - \alpha_i - \mu_i = 0$ì´ ì„±ë¦½í•˜ê¸° ìœ„í•´ $\mu_i > 0$ ì´ì–´ì•¼ í•¨. 
  â†’ $\mu_i > 0$ì´ë¼ë©´ $\mu_i\xi_i = 0$ì´ ì„±ë¦½í•˜ê¸° ìœ„í•´ $\xi_i = 0$ì´ì–´ì•¼ í•¨
  
    â†’ $y_i(\boldsymbol{w}^T\boldsymbol{x} + b)-1 = 0$ì¸ Instance
  
    â‡’ Margin ìœ„ì— ìœ„ì¹˜í•˜ëŠ” Support Vector
  
- **Case 3)** $\alpha_i = C \quad$
  â†’ $C - \alpha_i - \mu_i = 0$ì—ì„œ $\alpha_i = C$ë¼ë©´ $\mu_i = 0$
  
    â†’ $\mu_i = 0$ì´ë¼ë©´ $\xi_i > 0$
  
    â‡’ Margin ë°–ì— ìœ„ì¹˜í•˜ëŠ” Support Vector
  
    <p align = 'center'><img src = https://user-images.githubusercontent.com/56019094/199524486-539f4d6a-37fe-4882-bbf7-97188c7d06d2.png height = '300'></p>
  

Hyperparameter C(ì˜¤ë¶„ë¥˜ ë¹„ìš©)ì— ë”°ë¥¸ ë¶„ë¥˜ ê²½ê³„ë©´ ë³€í™”

<p align = 'center'><img src = https://user-images.githubusercontent.com/56019094/199524779-72b14258-12fb-4d6b-a601-8bf87d5f069d.png height = '300'></p>

$$
min \quad {1 \over 2}||\boldsymbol{w}||^2 +C\sum_{i=1}^N \xi_i
$$

Large C: ëª©ì í•¨ìˆ˜ì—ì„œ Penaltyê°€ ë” í° ì˜í–¥ë ¥ì„ ê°€ì§   
    â†’ Penaltyë¥¼ ì¤„ì´ëŠ” ë°©í–¥ìœ¼ë¡œ í•™ìŠµì´ ì§„í–‰  
    â†’ Marginì´ ì¢ê³ , $\alpha_i = C$ì¸ Support Vectorì˜ ìˆ˜ê°€ ìƒëŒ€ì ìœ¼ë¡œ ì ìŒ  

Small C: ëª©ì í•¨ìˆ˜ì—ì„œ Penaltyì˜ ì˜í–¥ë ¥ì´ ì‘ì•„ì§   
      â†’ Penaltyì˜ ì˜í–¥ë ¥ì´ ì ìœ¼ë¯€ë¡œ Marginì„ ì¡°ê¸ˆ ë” ë„“ê²Œ ì¡ì„ ìˆ˜ ìˆìŒ  
      â†’ $\alpha_i = C$ì¸ Support Vectorì˜ ìˆ˜ê°€ ìƒëŒ€ì ìœ¼ë¡œ ë§ìŒ  

>## Nonlinear & Kernel

- Linear Modelì˜ í•œê³„: ë¶„ë¥˜ ê²½ê³„ë©´ì´ ë¹„ì„ í˜•ì¼ ê²½ìš° ì˜ ì°¾ì•„ë‚´ì§€ í•¨
  
    <p align = 'center'><img src = https://user-images.githubusercontent.com/56019094/199524989-6ae5a362-d1ba-4a01-b749-1e0be33d5296.png height = '300'></p>
    


ğŸ§ ì„ í˜• ë¶„ë¥˜ê°€ ê°€ëŠ¥í•œ ê³ ì°¨ì›ìœ¼ë¡œ ë°ì´í„°ë¥¼ Mappingí•´ì„œ ëª¨ë¸ì„ í•™ìŠµí•˜ì!

<p align = 'center'><img src = https://user-images.githubusercontent.com/56019094/199525195-e5ee6860-9c28-48cf-a3fd-f86223d3b91c.png height = '300'></p>
ì´ë¯¸ì§€ ì¶œì²˜: [https://towardsdatascience.com/support-vector-machine-formulation-and-derivation-b146ce89f28]

â‡’ ê³ ì°¨ì› Mappingì„ í†µí•´ Nonlinear(ë¹„ì„ í˜•) ë¶„ë¥˜ ê²½ê³„ë©´ ìƒì„±

>>### ê³ ì°¨ì›ì—ì„œì˜ ëª©ì  í•¨ìˆ˜ ë° ì œì•½ ì¡°ê±´

$min\quad{1 \over 2}||\boldsymbol{w}||^2 + C\sum_{i=1}^N\xi_i$


$s.t\quad y_i(\boldsymbol{w}^T\Phi(\boldsymbol{x}_i) + b) \ge 1-\xi_i,\quad \xi_i \ge0, \quad\forall i$

â‡’ **ë¼ê·¸ë‘ì§€ì•ˆ ë¬¸ì œë¡œ ë³€í™˜**

$\min\quad{ L_{p}(\boldsymbol{w},b,{ \alpha  }_{ i }) }  =\frac { 1 }{ 2 } { \left\| \boldsymbol{w} \right\|  }^{ 2 } + {C\sum_{i=1}^N\xi_i}-\sum _{ i=1 }^{ N }{ { \alpha  }_{ i }({ y }_{ i }({ \boldsymbol{w} }^{ T }{ \Phi({\boldsymbol{x}_i)} }+b)-1 + \xi_i) } - \sum_{i=1}^N\mu_i\xi_i$

- KKT ì¡°ê±´
  
    ${\partial L_P \over \partial w} = 0\quad$â‡’ $\boldsymbol{w} = \sum_{i=1}^n\alpha_iy_i\Phi(\boldsymbol{x}_i)$
    
    ${\partial L_P \over \partial b} = 0\quad$â‡’ $\sum_{i=1}^n\alpha_iy_i = 0$
    
    ${\partial L_P \over \partial \xi_i} = 0\quad$â‡’ $C - \alpha_i - \mu_i = 0$
    

â‡’ ìŒëŒ€(Dual) ë¬¸ì œë¡œ ë³€í™˜

$max\quad L_D({\alpha_i}) = \sum_{i=1}^N\alpha_i  - {1 \over 2}\sum_{i=1}^N\sum_{j=1}^N\alpha_i\alpha_jy_iy_j\Phi(\boldsymbol{x}_i)^T\Phi(\boldsymbol{x}_j)$

$s.t.\quad \sum_{i=1}^N \alpha_iy_i = 0, 0 \le \alpha_i \le C$

ğŸ˜“ ê³ ì°¨ì›ìœ¼ë¡œ Mappingì‹œí‚¤ëŠ” í•¨ìˆ˜ $\Phi$ë¥¼ ì–´ë–»ê²Œ ì°¾ì„ê¹Œ,,,?

ğŸ‘ğŸ» Kernel Trickì„ ì“°ì!

$max\quad L_D({\alpha_i}) = \sum_{i=1}^N\alpha_i  - {1 \over 2}\sum_{i=1}^N\sum_{j=1}^N\alpha_i\alpha_jy_iy_j\Phi(\boldsymbol{x}_i)^T\Phi(\boldsymbol{x}_j)$

â‡’  $max\quad L_D({\alpha_i}) = \sum_{i=1}^N\alpha_i  - {1 \over 2}\sum_{i=1}^N\sum_{j=1}^N\alpha_i\alpha_jy_iy_j K(\boldsymbol{x}_i, \boldsymbol{x}_j)$

### Kernel Trick

$max\quad L_D({\alpha_i}) = \sum_{i=1}^N\alpha_i  - {1 \over 2}\sum_{i=1}^N\sum_{j=1}^N\alpha_i\alpha_jy_iy_j\Phi(\boldsymbol{x}_i)^T\Phi(\boldsymbol{x}_j)$ì—ì„œì™€ ê°™ì´ ê³ ì°¨ì›ì—ì„œëŠ” í•­ìƒ $\Phi({\boldsymbol{x}_i})^T\Phi(\boldsymbol{x}_j)$ì™€ ê°™ì´ ë²¡í„°ì˜ ë‚´ì  í˜•íƒœë¡œ ì¡´ì¬

â†’ ì €ì°¨ì› ë°ì´í„°ë¥¼ ì…ë ¥ ë°›ì•„ì„œ ê³ ì°¨ì› ê³µê°„ìƒì— ë‚´ì  ê²°ê³¼ê°’ì„ ì¤„ ìˆ˜ ìˆë‹¤ë©´ êµ³ì´ $\Phi$ë¥¼ ì°¾ì§€ ì•Šì•„ë„ ëœë‹¤!

<p align = 'center'><img src = https://user-images.githubusercontent.com/56019094/199525449-05428317-64ad-4ac0-bbc5-266015f5d493.png height = '300'></p>

- ìœ íš¨í•œ Kernel í•¨ìˆ˜ì˜ ì¡°ê±´
    - Symmetric Matrix
    - Positive semi-definite Matrix

- ëŒ€í‘œì ì¸ Kernel í•¨ìˆ˜
    - Polynomial
      
        $K(x,y) = (x \cdot y + c)^d,\quad c>0$
        
    - Gaussian (RBF)
      
        $K(x,y) = exp(-{||x-y||^2 \over 2\sigma^2}),\quad \sigma \ne 0$
        
    - Sigmoid
      
        $K(x,y) = tanh(a(x\cdot y)+b),\quad a,b\ge0$
    
- Kernel í˜•íƒœì— ë”°ë¥¸ ë¶„ë¥˜ ê²½ê³„ë©´
    - Linear Kernel: ì„ í˜• ë¶„ë¥˜ ê²½ê³„ë©´ë§Œ ìƒì„± ê°€ëŠ¥
    - Non-linear Kernel: ë³µì¡í•œ í˜•íƒœì˜ ë¶„ë¥˜ ê²½ê³„ë©´ ìƒì„± ê°€ëŠ¥
    
    
    <p align = 'center'><img src = https://user-images.githubusercontent.com/56019094/199525684-704acd32-74e6-4432-85ab-8d1c778c7dff.png height = '500'></p>
    ì´ë¯¸ì§€ ì¶œì²˜: [https://towardsdatascience.com/multiclass-classification-with-support-vector-machines-svm-kernel-trick-kernel-functions-f9d5377d6f02]



># **ì½”ë”© ì‹¤ìŠµ**

## ì‹¤í—˜ ì£¼ì œ

## *Main Experiment - Support Vector Classifier*

### SVC ê²°ê³¼ í•´ì„



## *Additional Experiment - Support Vector Regressor*

### SVR ê²°ê³¼ í•´ì„



