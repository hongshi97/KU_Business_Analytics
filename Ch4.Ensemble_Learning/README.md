# **Ensemble Learning**
- ë³¸ Tutorialì€ ê³ ë ¤ëŒ€í•™êµ ì‚°ì—…ê²½ì˜ê³µí•™ë¶€ ëŒ€í•™ì› Business Analytics ê°•ì˜ ìë£Œ ë° ì™¸ë¶€ ìë£Œë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì‘ì„±ë˜ì—ˆìŠµë‹ˆë‹¤.
- ë³¸ Tutorialì—ì„œëŠ” Ensemble ê¸°ë²• ì¤‘ Baggingì— ëŒ€í•œ ì„¤ëª…ê³¼ ì½”ë“œë¥¼ í•¨ê»˜ ì„¤ëª…í•˜ì˜€ìŠµë‹ˆë‹¤.

---
## Overview
<p align = 'center'>
<img src = 'https://user-images.githubusercontent.com/56019094/205027310-d6295e3b-441c-42b9-8c61-840448446ec5.png' width = 80%>
</p>

ğŸ¤” í˜¹ì‹œ êµ¬ìŠ¬ ìˆ˜ ì‹¤í—˜ì„ ì•„ì‹œë‚˜ìš”?  
: í•œ êµìˆ˜ê°€ ìœ ë¦¬ë³‘ì— ìœ ë¦¬ êµ¬ìŠ¬ 850ê°œë¥¼ ë„£ê³  í•™ìƒë“¤ì—ê²Œ ë³´ì—¬ì¤€ í›„, êµ¬ìŠ¬ì˜ ì´ ê°œìˆ˜ë¥¼ ë§ì¶°ë³´ë¼ê³  í–ˆìŠµë‹ˆë‹¤. í•™ìƒë“¤ì˜ ë‹µë³€ì˜ í‰ê· ê°’ì€ 871ê°œì˜€ìŠµë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ëª¨ë“  í•™ìƒë“¤ì˜ ê°œë³„ ë‹µë³€ ì¤‘ì—ëŠ” ì´ë³´ë‹¤ ë” ì •í™•í•œ ë‹µë³€ì€ ì—†ì—ˆë‹¤ê³  í•©ë‹ˆë‹¤.  

ê·¸ë¦¬ê³  ì˜¤ë¥¸ìª½ ê·¸ë¦¼ì— ë‚˜ì™€ìˆëŠ” ìœ„í‚¤í”¼ë””ì•„ëŠ” ëˆ„êµ¬ë‚˜ ììœ ë¡­ê²Œ ì“¸ ìˆ˜ ìˆëŠ” ì¸í„°ë„· ë°±ê³¼ì‚¬ì „ì…ë‹ˆë‹¤.  
ì´ ë‘ ê°œë¥¼ ì•„ìš°ë¥´ëŠ” í‚¤ì›Œë“œëŠ” ë°”ë¡œ ```ì§‘ë‹¨ ì§€ì„±```ì´ë¼ê³  í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë•Œë¡œëŠ” ë‹¤ìˆ˜ì˜ í‰ë²”í•œ ì‚¬ëŒë“¤ì´ ì†Œìˆ˜ì˜ ì „ë¬¸ê°€ë³´ë‹¤ ë‚˜ì€ íŒë‹¨ì„ í•˜ëŠ” ê²ƒì²˜ëŸ¼ ì—¬ëŸ¬ ì‚¬ëŒì´ ëª¨ì—¬ í˜‘ë ¥í•˜ê±°ë‚˜ ê²½ìŸí•´ì„œ ì–»ì€ ì§‘ë‹¨ì ì¸ ì§€ì  ëŠ¥ë ¥ì´ ë°”ë¡œ ì§‘ë‹¨ ì§€ì„±ì…ë‹ˆë‹¤.

ë¨¸ì‹  ëŸ¬ë‹ì— ë°”ë¡œ ì´ ì§‘ë‹¨ ì§€ì„±ì´ë¼ëŠ” ê°œë…ì„ ì ìš©í•œ ê²ƒì´ ```Ensemble```ì´ë¼ê³  ìƒê°í•˜ì‹œë©´ ì´í•´í•˜ê¸° ì‰¬ìš¸ ê²ƒ ê°™ìŠµë‹ˆë‹¤.

<p align = 'center'>
<img src = 'https://user-images.githubusercontent.com/56019094/205031265-5c2e9ccd-ba33-4643-9559-2b55f5545f03.png' width = 80%>
</p>


ì´ë¯¸ì§€ ì¶œì²˜: https://towardsdatascience.com/four-ways-teams-win-on-kaggle-50e62acb87f4  

Kaggleì—ì„œ ìƒìœ„ ë­í¬ê°€ ë˜ê¸° ìœ„í•´ì„œëŠ” Ensemble ê¸°ë²•ì€ í•„ìˆ˜ë¼ê³ ë“¤ í•©ë‹ˆë‹¤. ë¹„ë¡ ìœ„ ì‚¬ì§„ì€ 2020ë…„ ì‚¬ì§„ì´ì§€ë§Œ, Kaggleì˜ 120ê°œ Competitionsì—ì„œ Top-5 íŒ€ë“¤ì´ ì‚¬ìš©í•œ ë¨¸ì‹ ëŸ¬ë‹ ì†Œí”„íŠ¸ì›¨ì–´ë¥¼ ë³´ë©´ ì•™ìƒë¸” ê¸°ë²•ì¸ LightGBMê³¼ XGBoostê°€ ìƒìœ„ê¶Œì„ ì°¨ì§€í•˜ê³  ìˆìŠµë‹ˆë‹¤. ëˆˆì— ë„ëŠ” ê²ƒì€ Kerasë‚˜ PyTorch, TensorFlowì™€ ê°™ì€ ê²ƒì€ íŠ¹ì • ê¸°ë²•ì´ ì•„ë‹Œ í”„ë ˆì„ì›Œí¬ì¸ë°, LightGBMê³¼ XGBoostê°€ ê·¸ë³´ë‹¤ ë” ë§ì´ ì“°ì˜€ë‹¤ê³  í•˜ë„¤ìš”.

---
ì´ë²ˆ Tutorialì—ì„œëŠ” Ensemble ê¸°ë²•ì˜ ëŒ€ë¶„ë¥˜ë¼ê³  í•  ìˆ˜ ìˆëŠ” ```Bagging```ê³¼ ```Boosting``` ì¤‘ Baggingì— ëŒ€í•´ì„œ ì•Œì•„ë³´ê² ìŠµë‹ˆë‹¤. 

<p align = 'center'>
<img src = 'https://user-images.githubusercontent.com/56019094/205032202-a906c8e0-5004-431e-b735-af2918e399e6.png' width = 80%>
</p>

```Bagging```ì€ ìœ„ ê·¸ë¦¼ê³¼ ê°™ì´ ê° ëª¨ë¸ë“¤ì´ ë³‘ë ¬ ì²˜ë¦¬ê°€ ê°€ëŠ¥í•˜ë‹¤ëŠ” ì¥ì ì´ ìˆìŠµë‹ˆë‹¤. ë°˜ë©´ ```Boosting```ì€ Classifier1ì—ì„œ ë‚˜ì˜¨ í™”ì‚´í‘œê°€ ì˜¤ë¥¸ìª½ì— ìˆëŠ” Dataset Manipulatorë¡œ ì—°ê²°ë˜ì–´ ìˆëŠ” ê²ƒì²˜ëŸ¼ ê° ëª¨ë¸ë“¤ì„ ë³‘ë ¬ë¡œ ì²˜ë¦¬í•˜ëŠ” ê²ƒì´ ë¶ˆê°€ëŠ¥í•©ë‹ˆë‹¤. ëŒ€ì‹ , Baggingì€ ëª¨ë¸ ë³µì¡ë„ê°€ ë†’ì€ Artificial Neural Networkë‚˜ K(Small)-NNì„ Base Modelë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤. ë°˜ë©´, Baggingì€ Logistic Regressionì´ë‚˜ K(Large)-NNì„ ì‚¬ìš©í•©ë‹ˆë‹¤. ì´ì œ ê·¸ë ‡ë‹¤ë©´ Baggingì— ëŒ€í•´ì„œ ì¡°ê¸ˆ ë” ìì„¸íˆ ì•Œì•„ë³´ê² ìŠµë‹ˆë‹¤.

---
## Bagging
```Bagging```ì˜ í’€ ë„¤ì„ì€ ë°”ë¡œ ```B```ootstrapp ```Agg```regat```ing```ì…ë‹ˆë‹¤.  
Baggingì˜ íŠ¹ì§•ì€ ì•„ë˜ì™€ ê°™ìŠµë‹ˆë‹¤.
- Ensembleì˜ ê° ëª¨ë¸ì€ ì„œë¡œ ë‹¤ë¥¸ í•™ìŠµ ë°ì´í„°ì…‹ì„ ì´ìš©í•©ë‹ˆë‹¤.
- ê° ë°ì´í„°ì…‹ì€ **ë³µì› ì¶”ì¶œ**ì„ í†µí•´ **ì›ë˜** ë°ì´í„°ì…‹ì˜ ìˆ˜ë§Œí¼ì˜ **í¬ê¸°**ë¥¼ ê°–ë„ë¡ ìƒ˜í”Œë§í•´ì„œ ìƒì„±ë©ë‹ˆë‹¤.
- ì´ë ‡ê²Œ ìƒì„±ëœ ê°œë³„ ë°ì´í„°ì…‹ì„ **Bootstrap**(ë¶“ìŠ¤íŠ¸ë©)ì´ë¼ê³  í•©ë‹ˆë‹¤.
- Baggingì˜ íŠ¹ì´í•œ ì ì€ ë°”ë¡œ **ì›í•˜ëŠ” ê°œìˆ˜**ë§Œí¼ Bootstrapì„ ë§Œë“¤ ìˆ˜ ìˆë‹¤ëŠ” ê²ƒì…ë‹ˆë‹¤.

ì´ì œ ê·¸ë ‡ë‹¤ë©´ ì½”ë“œ ì˜ˆì‹œì™€ í•¨ê»˜ ì‚´í´ë³´ê² ìŠµë‹ˆë‹¤.  
íŠœí† ë¦¬ì–¼ì—ì„œëŠ” ë¨¸ì‹ ëŸ¬ë‹ì„ ì ‘í•´ë³´ì‹  ë¶„ë“¤ì´ë¼ë©´ ë‹¤ë“¤ í•œ ë²ˆì€ ì‚¬ìš©í•´ë³´ì…¨ì„ Titanic ë°ì´í„°ì…‹ì„ ì´ìš©í•˜ê² ìŠµë‹ˆë‹¤.  

#### Bootstrap ìƒì„± í•¨ìˆ˜
---
```python
# Bootstrap Dataset ìƒì„± í•¨ìˆ˜ ì •ì˜
def make_bs_data_list(train_X, train_y, bootstrap_num:int, verbose = 0) -> list:
    assert len(train_X) == len(train_y), "Your Train_X's length is not equal to Train_y's length"
    
    bootstrap_data_list = []
    
    total_index = set(range(len(train_X)))

    for i in range(bootstrap_num): # ë°ì´í„°ì…‹ì„ bootstrap_numë§Œí¼ ë°˜ë³µ ë³µì› ì¶”ì¶œ ì§„í–‰
        data_index = [data_index for data_index in range(train_X.shape[0])]
        random_data_index = np.random.choice(data_index, train_X.shape[0]) # ë³µì› ì¶”ì¶œ
        
        valid_index = list(total_index.difference(set(random_data_index)))

        bs_train_X = train_X.iloc[random_data_index,]
        bs_train_y = train_y.iloc[random_data_index,]
        bs_valid_X = train_X.iloc[valid_index,]
        bs_valid_y = train_y.iloc[valid_index,]

        bootstrap_data_list.append([bs_train_X,bs_train_y, bs_valid_X, bs_valid_y])

        if (valid_index != 0) & (verbose == 1):
            print(f"{i+1}ë²ˆì§¸ Bootstrapì„ ìƒì„±í•  ë•Œ í•œ ë²ˆë„ ì„ íƒë˜ì§€ ì•Šì€ Instanceê°€ ì¡´ì¬í•˜ì—¬ Validation Setì„ ìƒì„±í–ˆìŠµë‹ˆë‹¤.")
            print(f'Validation Setìœ¼ë¡œ ì‚¬ìš©ëœ Instanceì˜ ìˆ˜: {len(valid_index)} ({np.round(len(valid_index)/len(total_index)*100,2)}%) \n')

    return bootstrap_data_list
```
ìœ„ ì½”ë“œ ê²°ê³¼ ì˜ˆì‹œ
```
1ë²ˆì§¸ Bootstrapì„ ìƒì„±í•  ë•Œ í•œ ë²ˆë„ ì„ íƒë˜ì§€ ì•Šì€ Instanceê°€ ì¡´ì¬í•˜ì—¬ Validation Setì„ ìƒì„±í–ˆìŠµë‹ˆë‹¤.
Validation Setìœ¼ë¡œ ì‚¬ìš©ëœ Instanceì˜ ìˆ˜: 193 (36.14%) 

2ë²ˆì§¸ Bootstrapì„ ìƒì„±í•  ë•Œ í•œ ë²ˆë„ ì„ íƒë˜ì§€ ì•Šì€ Instanceê°€ ì¡´ì¬í•˜ì—¬ Validation Setì„ ìƒì„±í–ˆìŠµë‹ˆë‹¤.
Validation Setìœ¼ë¡œ ì‚¬ìš©ëœ Instanceì˜ ìˆ˜: 189 (35.39%) 

3ë²ˆì§¸ Bootstrapì„ ìƒì„±í•  ë•Œ í•œ ë²ˆë„ ì„ íƒë˜ì§€ ì•Šì€ Instanceê°€ ì¡´ì¬í•˜ì—¬ Validation Setì„ ìƒì„±í–ˆìŠµë‹ˆë‹¤.
Validation Setìœ¼ë¡œ ì‚¬ìš©ëœ Instanceì˜ ìˆ˜: 192 (35.96%) 

4ë²ˆì§¸ Bootstrapì„ ìƒì„±í•  ë•Œ í•œ ë²ˆë„ ì„ íƒë˜ì§€ ì•Šì€ Instanceê°€ ì¡´ì¬í•˜ì—¬ Validation Setì„ ìƒì„±í–ˆìŠµë‹ˆë‹¤.
Validation Setìœ¼ë¡œ ì‚¬ìš©ëœ Instanceì˜ ìˆ˜: 197 (36.89%) 

5ë²ˆì§¸ Bootstrapì„ ìƒì„±í•  ë•Œ í•œ ë²ˆë„ ì„ íƒë˜ì§€ ì•Šì€ Instanceê°€ ì¡´ì¬í•˜ì—¬ Validation Setì„ ìƒì„±í–ˆìŠµë‹ˆë‹¤.
Validation Setìœ¼ë¡œ ì‚¬ìš©ëœ Instanceì˜ ìˆ˜: 202 (37.83%) 

6ë²ˆì§¸ Bootstrapì„ ìƒì„±í•  ë•Œ í•œ ë²ˆë„ ì„ íƒë˜ì§€ ì•Šì€ Instanceê°€ ì¡´ì¬í•˜ì—¬ Validation Setì„ ìƒì„±í–ˆìŠµë‹ˆë‹¤.
Validation Setìœ¼ë¡œ ì‚¬ìš©ëœ Instanceì˜ ìˆ˜: 194 (36.33%) 

7ë²ˆì§¸ Bootstrapì„ ìƒì„±í•  ë•Œ í•œ ë²ˆë„ ì„ íƒë˜ì§€ ì•Šì€ Instanceê°€ ì¡´ì¬í•˜ì—¬ Validation Setì„ ìƒì„±í–ˆìŠµë‹ˆë‹¤.
Validation Setìœ¼ë¡œ ì‚¬ìš©ëœ Instanceì˜ ìˆ˜: 198 (37.08%) 

8ë²ˆì§¸ Bootstrapì„ ìƒì„±í•  ë•Œ í•œ ë²ˆë„ ì„ íƒë˜ì§€ ì•Šì€ Instanceê°€ ì¡´ì¬í•˜ì—¬ Validation Setì„ ìƒì„±í–ˆìŠµë‹ˆë‹¤.
Validation Setìœ¼ë¡œ ì‚¬ìš©ëœ Instanceì˜ ìˆ˜: 191 (35.77%) 

9ë²ˆì§¸ Bootstrapì„ ìƒì„±í•  ë•Œ í•œ ë²ˆë„ ì„ íƒë˜ì§€ ì•Šì€ Instanceê°€ ì¡´ì¬í•˜ì—¬ Validation Setì„ ìƒì„±í–ˆìŠµë‹ˆë‹¤.
Validation Setìœ¼ë¡œ ì‚¬ìš©ëœ Instanceì˜ ìˆ˜: 211 (39.51%) 
```

ì¡°ê¸ˆì”© ì½”ë“œë¥¼ ë‚˜ëˆ ì„œ ì‚´í´ë³´ê² ìŠµë‹ˆë‹¤.
```python
def make_bs_data_list(train_X, train_y, bootstrap_num:int, verbose = 0) -> list: 
    assert len(train_X) == len(train_y), "Your Train_X's length is not equal to Train_y's length"
    
    bootstrap_data_list = []
    
    total_index = set(range(len(train_X)))

```
- ìœ„ í•¨ìˆ˜ì— ë“¤ì–´ê°€ëŠ” Inputì„ ë³´ë‹ˆ Training Setì˜ Xì™€ Training Setì˜ Yê°€ ë“¤ì–´ê°€ëŠ” ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ê·¸ë¦¬ê³  ```bootstrap_num```ì´ë¼ëŠ” ì–´ë–¤ ```int(ì •ìˆ˜)```ê°€ ë“¤ì–´ê°€ëŠ” ê²ƒìœ¼ë¡œ ë³´ì…ë‹ˆë‹¤. ìœ„ ì„¤ëª…ì—ì„œ ì œê°€ "Baggingì˜ íŠ¹ì´í•œ ì ì€ ë°”ë¡œ **ì›í•˜ëŠ” ê°œìˆ˜**ë§Œí¼ Bootstrapì„ ë§Œë“¤ ìˆ˜ ìˆë‹¤ëŠ” ê²ƒ"ì´ë¼ê³  í–ˆëŠ”ë° ë°”ë¡œ ì—¬ê¸°ì„œ **ì›í•˜ëŠ” ê°œìˆ˜**ë¥¼ ```bootstrap_num```ì— ì…ë ¥í•´ì£¼ë©´ ë©ë‹ˆë‹¤.


ì•„ë˜ ì½”ë“œê°€ ë°”ë¡œ Baggingì˜ í•µì‹¬ì¸ Bootstrapì„ ë§Œë“œëŠ” íŒŒíŠ¸ì…ë‹ˆë‹¤. ì•„ë˜ ì½”ë“œë¥¼ ë‹¤ì‹œ ì¡°ê¸ˆì”© ë‚˜ëˆ ì„œ ì‚´í´ë³´ê² ìŠµë‹ˆë‹¤.
```python
    for i in range(bootstrap_num): # ë°ì´í„°ì…‹ì„ bootstrap_numë§Œí¼ ë³µì› ì¶”ì¶œ ì§„í–‰
        data_index = [data_index for data_index in range(train_X.shape[0])] # Training Setì˜ Instanceì˜ indexë¥¼ 0ë¶€í„° ëê¹Œì§€ ë¦¬ìŠ¤íŠ¸ í˜•íƒœë¡œ ì €ì¥
        random_data_index = np.random.choice(data_index, train_X.shape[0]) # ë³µì› ì¶”ì¶œ
        
        valid_index = list(total_index.difference(set(random_data_index)))

        bs_train_X = train_X.iloc[random_data_index,]
        bs_train_y = train_y.iloc[random_data_index,]
        bs_valid_X = train_X.iloc[valid_index,]
        bs_valid_y = train_y.iloc[valid_index,]

        bootstrap_data_list.append([bs_train_X,bs_train_y, bs_valid_X, bs_valid_y])
```
<p align = 'center'>
<img src = "https://user-images.githubusercontent.com/56019094/205035487-a164b133-26fb-4bf9-a377-c5d9d3c6441b.png">
</p>

Original Datasetì—ëŠ” ì›ë˜ Indexê°€ 1ë¶€í„° ìˆœì„œëŒ€ë¡œ ì¡´ì¬í•©ë‹ˆë‹¤. ì´ Index ê°’ë“¤ì„ ì €ì¥í•˜ëŠ” ê²ƒì´ ë°”ë¡œ ì•„ë˜ Lineì…ë‹ˆë‹¤.
```python 
data_index = [data_index for data_index in range(train_X.shape[0])]
```
ê·¸ë¦¬ê³  ê·¸ë¦¼ì— ë‚˜ì™€ìˆë“¯ì´ ê° Bootstrapì˜ Xì™€ yë¥¼ ë³´ë©´ Original Datasetê³¼ Indexê°€ ë‹¤ë¥¸ ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì•„ë˜ Lineì„ í†µí•´ ì›ë˜ Indexì— Random Permutationì„ ì ìš©í•´ì„œ Indexë¥¼ ë¬´ì‘ìœ„ë¡œ ì„ì–´ì¤ë‹ˆë‹¤.
```python
random_data_index = np.random.choice(data_index, train_X.shape[0])
```
ì´ì œ ë¬´ì‘ìœ„ë¡œ ì„ì¸ indexë¥¼ í†µí•´ ê°œë³„ Bootstrapì„ ìƒì„±í•˜ê²Œ ë©ë‹ˆë‹¤.
```python
valid_index = list(total_index.difference(set(random_data_index)))

bs_train_X = train_X.iloc[random_data_index,]
bs_train_y = train_y.iloc[random_data_index,]
bs_valid_X = train_X.iloc[valid_index,]
bs_valid_y = train_y.iloc[valid_index,]

bootstrap_data_list.append([bs_train_X,bs_train_y, bs_valid_X, bs_valid_y])
```
ğŸ™„ ê·¸ëŸ°ë° ì—¬ê¸°ì„œ ê°‘ìê¸° Trainì´ ì•„ë‹Œ ```valid```ë¼ëŠ” ë‹¨ì–´ê°€ ë“±ì¥í•©ë‹ˆë‹¤. ì´ê²ƒì€ ë°”ë¡œ Bootstrapì„ ìƒì„±í•  ë•Œ **ë³µì› ì¶”ì¶œ**ì„ í†µí•´ **ì›ë˜ ë°ì´í„°ì…‹ í¬ê¸°**ì™€ ë™ì¼í•œ í¬ê¸°ì˜ ```Bootstrapì„ ë§Œë“œëŠ”ë° ì„ íƒë˜ì§€ ëª»í•œ Instance```ë“¤ì„ ```Validation Set```ìœ¼ë¡œ ì‚¬ìš©í•˜ê¸° ìœ„í•¨ì…ë‹ˆë‹¤.

<p align = 'center'>
<img src = "https://user-images.githubusercontent.com/56019094/205039243-a161c0f5-9415-49e5-8207-6334007a725d.png" >
</p>

- N: Data Instanceì˜ ìˆ˜  
- 1/N: ê° Instanceê°€ Bootstrapì— ì„ íƒë  í™•ë¥   

ì¦‰, $p$ëŠ” í•œ Instanceê°€ í•˜ë‚˜ì˜ Bootstrapì— ë‹¨ í•œë²ˆë„ ì„ íƒë˜ì§€ ì•Šì„ í™•ë¥ ì…ë‹ˆë‹¤. Data Instanceì˜ ìˆ˜ Nì„ ë¬´í•œëŒ€ë¡œ ë³´ë‚´ë©´ ê²°êµ­ $p$ = 0.368 ì¦‰, í•œ Instanceê°€ í•˜ë‚˜ì˜ Bootstrapì— ë‹¨ í•œë²ˆë„ ì„ íƒë˜ì§€ ì•Šì„ í™•ë¥ ì€ 36.8%ë‚˜ ë©ë‹ˆë‹¤.
ì´ëŸ¬í•œ ì„ íƒë˜ì§€ ì•Šì€ Data Instanceë“¤(=OOB Data)ëŠ” ì´í›„ì— Validation Setìœ¼ë¡œ ì‚¬ìš©ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  
ì´ì œ ì €ê¸°ì„œ ```valid```ê°€ ì™œ ìˆëŠ”ì§€ ì´í•´ê°€ ë˜ì‹¤ ê²ƒ ê°™ìŠµë‹ˆë‹¤. total_index(Training Setì˜ ëª¨ë“  Index)ì—ì„œ random_data_index(Bootstrapìœ¼ë¡œ ë½‘íŒ Instanceë“¤ì˜ Index)ì˜ ì°¨ì§‘í•©ì„ í†µí•´ **ë‹¨ í•œë²ˆë„ Bootstrapìœ¼ë¡œ ì„ íƒë˜ì§€ ì•Šì€ Index**ë“¤ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤.

ê·¸ë¦¬ê³  ì‚¬ì‹¤ ì´ë¯¸ ì½”ë“œ ê²°ê³¼ë¥¼ ì´ì „ì— ë³´ì…¨ê² ì§€ë§Œ, ì‹¤ì œë¡œ 
```
1ë²ˆì§¸ Bootstrapì„ ìƒì„±í•  ë•Œ í•œ ë²ˆë„ ì„ íƒë˜ì§€ ì•Šì€ Instanceê°€ ì¡´ì¬í•˜ì—¬ Validation Setì„ ìƒì„±í–ˆìŠµë‹ˆë‹¤.
Validation Setìœ¼ë¡œ ì‚¬ìš©ëœ Instanceì˜ ìˆ˜: 193 (36.14%) 

2ë²ˆì§¸ Bootstrapì„ ìƒì„±í•  ë•Œ í•œ ë²ˆë„ ì„ íƒë˜ì§€ ì•Šì€ Instanceê°€ ì¡´ì¬í•˜ì—¬ Validation Setì„ ìƒì„±í–ˆìŠµë‹ˆë‹¤.
Validation Setìœ¼ë¡œ ì‚¬ìš©ëœ Instanceì˜ ìˆ˜: 189 (35.39%) 

3ë²ˆì§¸ Bootstrapì„ ìƒì„±í•  ë•Œ í•œ ë²ˆë„ ì„ íƒë˜ì§€ ì•Šì€ Instanceê°€ ì¡´ì¬í•˜ì—¬ Validation Setì„ ìƒì„±í–ˆìŠµë‹ˆë‹¤.
Validation Setìœ¼ë¡œ ì‚¬ìš©ëœ Instanceì˜ ìˆ˜: 192 (35.96%) 

4ë²ˆì§¸ Bootstrapì„ ìƒì„±í•  ë•Œ í•œ ë²ˆë„ ì„ íƒë˜ì§€ ì•Šì€ Instanceê°€ ì¡´ì¬í•˜ì—¬ Validation Setì„ ìƒì„±í–ˆìŠµë‹ˆë‹¤.
Validation Setìœ¼ë¡œ ì‚¬ìš©ëœ Instanceì˜ ìˆ˜: 197 (36.89%) 

5ë²ˆì§¸ Bootstrapì„ ìƒì„±í•  ë•Œ í•œ ë²ˆë„ ì„ íƒë˜ì§€ ì•Šì€ Instanceê°€ ì¡´ì¬í•˜ì—¬ Validation Setì„ ìƒì„±í–ˆìŠµë‹ˆë‹¤.
Validation Setìœ¼ë¡œ ì‚¬ìš©ëœ Instanceì˜ ìˆ˜: 202 (37.83%) 
```
ì´ì™€ ê°™ì´ ```Bootstrapì— ë‹¨ í•œë²ˆë„ ì„ íƒë˜ì§€ ì•Šì€ Instanceì˜ ìˆ˜```ê°€ ì´ì „ ìˆ˜ì‹ì—ì„œ ë³´ì•˜ë˜ ì´ë¡ ì ì¸ í™•ë¥  36.8%ì™€ ìœ ì‚¬í•¨ì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. 

ì´ì œ ì œê°€ ì›í•˜ëŠ” ë§Œí¼ì˜ Bootstrapì„ ìƒì„±í•´ë³´ê² ìŠµë‹ˆë‹¤. 9ê°œì˜ Bootstrapì„ ìƒì„±í•´ì„œ í•˜ë‚˜ì˜ Listì¸ ```bs_data_list```ì— ë‹´ì•„ë†“ê² ìŠµë‹ˆë‹¤.
```python
# bs_data_list = [[Bootstrap1's train_X, Bootstrap1's train_Y, Bootstrap1's valid_X, Bootstrap1's valid_Y], ...]
bs_data_list = make_bs_data_list(train_X, train_y, 9, verbose = 1) 
```

ì´ì œ ê·¸ë ‡ë‹¤ë©´ Ensemble ëª¨ë¸ì— ì‚¬ìš©í•  Base Modelì„ ì •ì˜í•´ë³´ê² ìŠµë‹ˆë‹¤.  
ì´ì „ì— ì œê°€ Baggingì—ëŠ” ëª¨ë¸ ë³µì¡ë„ê°€ ë†’ì€ Artificial Neural Networkë‚˜ K(Small)-NNì„ Base Modelë¡œ ì‚¬ìš©í•œë‹¤ê³  í–ˆìŠµë‹ˆë‹¤. ê·¸ëŸ°ë° ê³¼ì—° **ëª¨ë¸ ë³µì¡ë„ê°€ ë‚®ì€ ëª¨ë¸ì¸ Decision Treeë‚˜ Logistic Regressionì„ ì‚¬ìš©í•˜ë©´ ìµœì¢… Ensemble ëª¨ë¸ì˜ ì„±ëŠ¥**ì´ ì–´ë–»ê²Œ ë ì§€ ê¶ê¸ˆí•´ì„œ ì§ì ‘ ì‹¤í—˜í•´ë³´ì•˜ìŠµë‹ˆë‹¤. 

```python
from sklearn.tree import DecisionTreeClassifier

def make_classifier(bs_data_list:list, bootstrap_num:int ,dt_max_depth:int, max_leaf_nodes:int):
    '''
    input: bs_data_list, bootstrap_num, dt_max_depth
    output: decision_trees

    boostrap_num: Should be same number(int) that used ini "make_bs_data_list" function
    '''
    models_list = []

    for idx, xy in enumerate(range(bootstrap_num)):
        train_x, train_y = bs_data_list[xy][0], bs_data_list[xy][1]
        globals()['{}_th_dt'.format(idx)] = DecisionTreeClassifier(max_depth = dt_max_depth, max_leaf_nodes= max_leaf_nodes).fit(train_x,train_y)
        models_list.append(globals()['{}_th_dt'.format(idx)])
    
    return models_list
```
ê·¸ë¦¬ê³  í•œë²ˆ ```Base Modelì˜ ì„±ëŠ¥ ì°¨ì´ê°€ ì¡´ì¬í•˜ëŠ” ê²½ìš° ìµœì¢… Ensemble ëª¨ë¸ì˜ ì„±ëŠ¥ì—ë„ ì–´ëŠ ì •ë„ ì°¨ì´ê°€ ìˆëŠ”ì§€``` í™•ì¸í•´ë³´ê¸° ìœ„í•´ ë‹¤ìŒê³¼ ê°™ì€ ì½”ë“œë¥¼ ì‚¬ìš©í–ˆìŠµë‹ˆë‹¤. ì¦‰, Decision Treeì˜ max_depthë¥¼ 1, 2, 4, 8ë¡œ ì„¤ì •í•´ì„œ [max_depth = 1ì¸ Decision Treeê°€ Bootstrap ìˆ˜ë§Œí¼ ìˆëŠ” Group, max_depth = 2ì¸ Decision Treeê°€ Bootstrap ìˆ˜ë§Œí¼ ìˆëŠ” Group, ...]ê³¼ ê°™ì´ ëª¨ë¸ì„ ìˆ˜ë¦½í•´ì„œ Base Model Group"ë“¤"ì´ë¼ëŠ” ì˜ë¯¸ë¡œ bm_groupsë¼ëŠ” List í˜•íƒœì˜ ë³€ìˆ˜ì— ì €ì¥í–ˆìŠµë‹ˆë‹¤.
```python
# bm_groups = [max_depth = 1ì¸ Base Modelë“¤ë¡œ êµ¬ì„±ëœ ì²«ë²ˆì§¸ ì•™ìƒë¸”ì— ì‚¬ìš©ë  ëª¨ë¸ë“¤, max_depth = 2ì¸ Base Modelë“¤ë¡œ êµ¬ì„±ëœ ë‘ë²ˆì§¸ ì•™ìƒë¸”ì— ì‚¬ìš©ë  ëª¨ë¸ë“¤, ... ]
bm_groups = []

for i in [1,2,4,8]:
    globals()['{}_dt_group'.format(i)] = make_classifier(bs_data_list, bootstrap_num = 9, dt_max_depth= i, max_leaf_nodes= 10)
    bm_groups.append(globals()['{}_dt_group'.format(i)])
```

ë¡œì§€ìŠ¤í‹± íšŒê·€ëª¨í˜•ì˜ ê²½ìš°, í•˜ì´í¼ íŒŒë¼ë¯¸í„° Cê°’ì— ë”°ë¼ ëª¨ë¸ì´ Training Setì— Over-fittingì´ ë  ìˆ˜ë„ í˜¹ì€ Under-fittingì´ ë  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤. ì´ë²ˆ íŠœí† ë¦¬ì–¼ì—ì„œëŠ” Base Modelì˜ ì„±ëŠ¥ ì°¨ì´ë¥¼ ìœ ë°œí•˜ê¸° ìœ„í•´ ê³ ì˜ì ìœ¼ë¡œ ì•„ë˜ì™€ ê°™ì´ C ê°’ì˜ ë²”ìœ„ë¥¼ ì¼ë°˜ì ìœ¼ë¡œ ì‚¬ìš©í•˜ëŠ” ê²½ìš°ë³´ë‹¤ ì¡°ê¸ˆ ë” ë„“ì€ ë²”ìœ„ë¡œ ë¡œì§€ìŠ¤í‹± íšŒê·€ëª¨í˜•ì„ ìˆ˜ë¦½í–ˆìŠµë‹ˆë‹¤. ì „ì²´ì ì¸ ì½”ë“œ íë¦„ì€ Decision Treeì™€ ë™ì¼í•©ë‹ˆë‹¤.
```python
from sklearn.linear_model import LogisticRegression

def make_classifier(bs_data_list:list, bootstrap_num:int, C:float):
    models_list = []

    for idx, xy in enumerate(range(bootstrap_num)):
        train_x, train_y = bs_data_list[xy][0], bs_data_list[xy][1]
        globals()['{}_th_dt'.format(idx)] = LogisticRegression(C = C).fit(train_x,train_y)
        models_list.append(globals()['{}_th_dt'.format(idx)])
    
    return models_list
```
```python
# ë¡œì§€ìŠ¤í‹± íšŒê·€ë¶„ì„ í•˜ì´í¼ íŒŒë¼ë¯¸í„° ì¤‘ C ê°’ ë³€í™”
bm_groups = []

for c in [0.001, 0.01, 0.1, 1, 5, 10, 100]:
    globals()['{}_dt_group'.format(i)] = make_classifier(bs_data_list, bootstrap_num= 9, C = c)
    bm_groups.append(globals()['{}_dt_group'.format(i)])

```



<p align = 'center'>
<img src = "https://user-images.githubusercontent.com/56019094/205043363-9ec1a308-7f8d-4ba3-af2a-62ad17eceaf7.png" width = 100%>
</p>

ìœ„ ê·¸ë¦¼ì—ì„œ ì €í¬ëŠ” ì´ì œ Step2ê¹Œì§€ ì™„ë£Œí–ˆìŠµë‹ˆë‹¤. ì¦‰,  
1. ì›ë˜ Training Setì„ ì´ìš©í•´ì„œ ì›í•˜ëŠ” ê°œìˆ˜ë§Œí¼ì˜ Bootstrapì„ ìƒì„±í•˜ê³ ,
2. ê° Bootstrapì„ ì´ìš©í•´ Base Modelì„ ê°ê° ìˆ˜ë¦½í–ˆìŠµë‹ˆë‹¤.  

ì´ì œ ê·¸ë ‡ë‹¤ë©´ Step 3:Model forecasting(ê°œë³„ Modelì˜ ì˜ˆì¸¡ê°’ êµ¬í•˜ê¸°)ì™€ Step 4: Result Aggregating(ê°œë³„ Modelì˜ ì˜ˆì¸¡ê°’ í•©ì¹˜ê¸°)ê°€ ë‚¨ì•˜ìŠµë‹ˆë‹¤. 

Ensemble Modelë¡œ í’€ê³ ì í•˜ëŠ” ë¬¸ì œê°€ Classification(ë¶„ë¥˜)ì¸ì§€, Regression(íšŒê·€)ì¸ì§€ì— ë”°ë¼ ê°œë³„ Modelì˜ ì˜ˆì¸¡ê°’ì„ í•©ì¹˜ëŠ” ë°©ë²•ì€ Votingì„ ì‚¬ìš©í•˜ê±°ë‚˜ Averagingì„ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë³¸ Tutorialì—ì„œëŠ” **Titanic** Datasetì„ ì´ìš©í•´ì„œ ì–´ë–¤ Instance(ì‚¬ëŒ)ì´ ```Survived(ìƒì¡´) ì—¬ë¶€```ë¥¼ ì˜ˆì¸¡í•˜ê³ ì í•˜ê¸° ë•Œë¬¸ì— ```Voting```ì„ ì´ìš©í•˜ê² ìŠµë‹ˆë‹¤.

<p align = 'center'>
<img src = "https://user-images.githubusercontent.com/56019094/205046452-30780e2c-eefa-4d1a-8040-bc82715cf0b3.png">
</p>

Votingì—ëŠ” Majority Voting, Weighted Majority Voting ë“±ì˜ ë°©ë²•ì´ ìˆìŠµë‹ˆë‹¤. ë³¸ Tutorialì—ì„œëŠ” ê°€ì¥ ì§ê´€ì ì¸ ë°©ë²•ì¸ Majority Votingì„ ì´ìš©í•´ì„œ ê°œë³„ Modelì˜ ê²°ê³¼ê°’ì„ í•©ì³ ìµœì¢… ì˜ˆì¸¡ê°’ì„ ë°˜í™˜í•˜ê² ìŠµë‹ˆë‹¤.  

Majority Voting êµ¬í˜„ ì½”ë“œëŠ” ë§¤ìš° ê°„ë‹¨í•©ë‹ˆë‹¤.
```python
def majority_voting(bm_group:list, test_X):
    preds_per_bm_group = [bm.predict(test_X) for bm in bm_group]
    mv_pred = pd.DataFrame(preds_per_bm_group).T.mode(axis = 1)

    return mv_pred
```
- Inputìœ¼ë¡œëŠ” Base Model Group ì¦‰, [Base Model 1, Base Model 2, ..., Base Model B]ì™€ ê°™ì´ Ensembleì— ì‚¬ìš©í•˜ê²Œ ë  Base Modelë“¤ì˜ Listë¥¼ ë°›ìŠµë‹ˆë‹¤.
- preds_per_bm_groupì€ Base Model Group ë‚´ì˜ ê° Base Modelì„ ì´ìš©í•´ Test Setì— ëŒ€í•œ Inference ê²°ê³¼ë“¤ì„ í•©ì¹œ Listì…ë‹ˆë‹¤.
- ê·¸ë¦¬ê³  .mode() ë©”ì„œë“œë¥¼ ì´ìš©í•´ **ìµœë¹ˆê°’**ì„ êµ¬í•´ì£¼ë©´ ì´ê²ƒì´ ë°”ë¡œ Majority Votingì„ í•œ ê²°ê³¼ì…ë‹ˆë‹¤.

ì´ì œ ê·¸ë ‡ë‹¤ë©´ Decision Treeì˜ max_depthë¥¼ ë³€ê²½í•´ê°€ë©° Base Model Groupì„ ìˆ˜ë¦½í•œ ê²°ê³¼(F1 Score)ë¥¼ ë³´ê² ìŠµë‹ˆë‹¤. Red Lineì€ Base Modelë“¤ì„ í•©ì³ Majority Votingì„ í†µí•´ ì–»ì€ ìµœì¢… ì˜ˆì¸¡ê°’ì„ ì´ìš©í•œ ì¦‰, Ensembleì˜ ì„±ëŠ¥ì…ë‹ˆë‹¤.

- Max_Depth = 2
<p align = 'center'>
<img src = "https://user-images.githubusercontent.com/56019094/205061175-cfe736ed-ac4c-4b2e-ab7e-67aaded023db.png" width = 80%>
</p>

- Max_Depth = 4
<p align = 'center'>
<img src = "https://user-images.githubusercontent.com/56019094/205061575-8c7d0d94-7672-4a17-8255-54b1e5e82323.png" width = 80%>
</p>

- Max_Depth = 8
<p align = 'center'>
<img src = "https://user-images.githubusercontent.com/56019094/205061702-f06f608a-86a7-46e1-840c-9aa8891527d2.png" width = 80%>
</p>

- Max_Depth = 16
<p align = 'center'>
<img src = "https://user-images.githubusercontent.com/56019094/205061803-02d45880-f2e8-4ee8-ba04-2f52656c33b3.png" width = 80%>
</p>


ê²°ê³¼

- Max_Depth = 2ì¸ ê²½ìš° Ensemble ê²°ê³¼ ì„±ëŠ¥ì´ Best Single Modelë³´ë‹¤ í˜„ì €íˆ ë‚®ì€ ì„±ëŠ¥ì„ ë³´ì´ê³  ìˆìŠµë‹ˆë‹¤. 
- ë°˜ë©´ **Max_Depth = 4ì¸ ê²½ìš° Ensemble ê²°ê³¼ ì„±ëŠ¥ì´ Best Single Modelë³´ë‹¤ ë†’ì€ ì„±ëŠ¥**ì„ ë³´ì´ë©° Ensembleì„ í†µí•´ ì§‘ë‹¨ ì§€ì„±ì˜ í˜ì„ ë³´ì—¬ì£¼ì—ˆìŠµë‹ˆë‹¤. 
- ê·¸ë¦¬ê³  Max_Depth = 8, 16ì¸ ê²½ìš°ëŠ” Ensemble ì„±ëŠ¥ì´ ê°ê° Best Single Modelë³´ë‹¤ ì•½ê°„ ë‚®ì€ ì„±ëŠ¥ì„ ë³´ì´ê³  ìˆìŠµë‹ˆë‹¤.

ê²°ê³¼ í•´ì„

- Max_Depth = 2ì¸ ê²½ìš° 9ê°œì˜ Base Model ì¤‘ 8ê°œì˜ ì„±ëŠ¥ì´ ë™ì¼í•œ ê²ƒìœ¼ë¡œ ìœ ì¶”í•´ë³´ì•„ ```Base Modelì˜ ë‹¤ì–‘ì„±```ì´ ë§¤ìš° ë‚®ì•„ Ensembleì˜ íš¨ê³¼ê°€ ê±°ì˜ ì—†ì—ˆë˜ ê²ƒìœ¼ë¡œ ë³´ì…ë‹ˆë‹¤. 

- Base Model ìì²´ì˜ ì„±ëŠ¥ ì°¨ì´ì— ë”°ë¥¸ ìµœì¢… Ensemble ì„±ëŠ¥ì˜ ë³€í™”ë¼ëŠ” ê´€ì ì—ì„œ ë³´ë©´, Max_Depth = 2ì˜ Base Model ì„±ëŠ¥ì´ ê°€ì¥ ë‚®ê³  ì‹¤ì œë¡œ Ensemble ì„±ëŠ¥ì´ ê°€ì¥ ë‚®ì€ ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë˜í•œ Max_Depth = 8, 16ì€ Base Modelì˜ ì„±ëŠ¥ì´ ê±°ì˜ ìœ ì‚¬í•¨ì— ë”°ë¼ Ensemble ì„±ëŠ¥ ë˜í•œ ê±°ì˜ ë™ì¼í•œ ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. 

- Random Forestì˜ ê²½ìš° Baggingì„ ì´ìš©í•œ ëŒ€í‘œì ì¸ ì•™ìƒë¸” ê¸°ë²•ì…ë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜, ë³¸ íŠœí† ë¦¬ì–¼ì—ì„œ Decision Treeì— ë‹¨ìˆœíˆ Baggingì„ í•œ ê²ƒê³¼ ì°¨ì´ì ì€ ë°”ë¡œ **ê°œë³„ Decision Tree**ë¥¼ ìˆ˜ë¦½í•˜ëŠ” ë° ì‚¬ìš©ë˜ëŠ” **ë…ë¦½ ë³€ìˆ˜ê°€ ë‹¤ë¥´ë‹¤**ëŠ” ê²ƒì…ë‹ˆë‹¤. ì¦‰, ë³¸ íŠœí† ë¦¬ì–¼ì—ì„œ Decision Treeì— Baggingì„ ì ìš©í•œ íš¨ê³¼ê°€ ë¯¸ë¯¸í•œ ê²ƒì€ Ensemble ëª¨ë¸ì˜ íš¨ê³¼ì— ì¤‘ìš”í•œ ìš”ì¸ì¸ **ê°œë³„ Base Modelì˜ "Diversity"**ê°€ ë¶€ì¡±í–ˆë˜ ê²ƒì´ ê°€ì¥ í° ìš”ì¸ì´ë¼ê³  íŒë‹¨í–ˆìŠµë‹ˆë‹¤.
---
ë¡œì§€ìŠ¤í‹± íšŒê·€ ëª¨í˜•ì„ ê¸°ë°˜ìœ¼ë¡œ í•˜ì´í¼ íŒŒë¼ë¯¸í„° Cë¥¼ ë³€í™”ì‹œí‚¤ë©° ì¶”ê°€ ì‹¤í—˜ì„ ì§„í–‰í•œ ê²°ê³¼ì…ë‹ˆë‹¤.

- C = 0.00001
<p align = 'center'>
<img src = "https://user-images.githubusercontent.com/56019094/205069090-4cfcaf22-a55d-4903-914f-ae688c6c4448.png" width = 80%>
</p>

- C = 0.001
<p align = 'center'>
<img src = "https://user-images.githubusercontent.com/56019094/205069314-27d137fb-5fee-48e2-9646-9f10e7a1dc4d.png" width = 80%>
</p>


- C = 1
<p align = 'center'>
<img src = "https://user-images.githubusercontent.com/56019094/205069580-c838edc7-b1ab-4a65-adbe-6e33552d0014.png" width = 80%>
</p>

- C = 100, 10000ì˜ ê²½ìš° ì„±ëŠ¥ì´ C = 1ì¸ ê²½ìš°ì™€ ê±°ì˜ ë™ì¼í–ˆê¸°ì— ê²°ê³¼ì—ì„œ ì œì™¸í–ˆìŠµë‹ˆë‹¤.  

|Model|C = 1|C=100|C=10000|
|-----|-----|-----|-------|
|BM1|0.7559|0.7619|0.7619|
|BM2|0.768|0.7559|0.7619|
|BM3|0.7656|0.7559|0.7656|
|BM4|0.7538|0.7538|0.7538|
|BM5|0.7559|0.75|0.75|
|BM6|0.7559|0.7442|0.7442|
|BM7|0.75|0.7442|0.7442|
|BM8|0.7559|0.7559|0.7559|
|BM9|0.7805|0.7667|0.7769|
|Ensemble|0.7559|0.75|0.75

ê²°ê³¼  

- C = 0.00001ì¸ ê²½ìš° Base Modelì˜ ì„±ëŠ¥(F1 Score) ìì²´ê°€ ë‚®ì•„ Ensemble ëª¨ë¸ì˜ ì„±ëŠ¥ë„ F1 Score ì•½ 0.38ë¡œ ë‚®ì€ ì„±ëŠ¥ì„ ë³´ì˜€ìŠµë‹ˆë‹¤.  
- C = 0.001ì¸ ê²½ìš° Base Modelì˜ ì„±ëŠ¥ì´ C = 0.00001ì¸ ê²½ìš°ë³´ë‹¤ëŠ” ëª¨ë‘ ë†’ì•„ Ensemble ê²°ê³¼ë„ F1 Score ì•½ 0.42ë¡œ ì¡°ê¸ˆ ë” ë†’ì€ ì„±ëŠ¥ì„ ë³´ì˜€ìŠµë‹ˆë‹¤.
- C = 1ì¸ ê²½ìš° Base Model ìì²´ì˜ ì„±ëŠ¥ì´ ì•½ 0.75ë¡œ ë†’ì•„ ë‹¹ì—°íˆ Ensemble ëª¨ë¸ì˜ F1 Scoreê°€ ì•½ 0.76ìœ¼ë¡œ ì´ì „ ë‘ ê²½ìš°ë³´ë‹¤ ë†’ì€ ì„±ëŠ¥ì„ ë³´ì˜€ìŠµë‹ˆë‹¤.  

ê²°ê³¼ í•´ì„
- í•´ë‹¹ ì‹¤í—˜ì„ í†µí•´ Ensembleì„ í†µí•´ ë†’ì€ ì„±ëŠ¥ì„ ì–»ê¸° ìœ„í•´ì„œëŠ” ìš°ì„ ì ìœ¼ë¡œ Base Model ìì²´ì˜ ì„±ëŠ¥ì´ ë’·ë°›ì¹¨ ë˜ì–´ì•¼ í•¨ì„ ì§ì ‘ ì‹¤í—˜ ê²°ê³¼ë¡œ ë‹¤ì‹œ í•œ ë²ˆ ë” í™•ì¸í•  ìˆ˜ ìˆì—ˆìŠµë‹ˆë‹¤. ì§‘ë‹¨ ì§€ì„±ì´ë¼ëŠ” ê²ƒë„ ì‚¬ì‹¤ì€ ì–´ëŠ ì •ë„ ì´ìƒì˜ ì§€ì‹ì„ ê°€ì§„ ì‚¬ëŒë“¤ì´ ëª¨ì—¬ì•¼ ì¢‹ì€ ê²°ê³¼ë¥¼ ì•¼ê¸°í•  ìˆ˜ ìˆë“¯ì´, Ensembleì—ì„œë„ ê°œë³„ Base Modelì˜ ì„±ëŠ¥ì´ ì–´ëŠ ì •ë„ ì¤€ìˆ˜í•œ ì„±ëŠ¥ì„ ë³´ì—¬ì•¼ ì´ëŸ¬í•œ Modelë“¤ì„ Ensembleí•˜ëŠ” ê²ƒì´ íš¨ê³¼ë¥¼ ë‚¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. 

ê²°ë¡ 
- Ensembleì„ í†µí•´ ê°œë³„ Base Modelë³´ë‹¤ ë” ì¢‹ì€ ì„±ëŠ¥ì„ ì–»ê¸° ìœ„í•´ì„œëŠ” ```ê°œë³„ Base Modelì˜ ë‹¤ì–‘ì„±```ê³¼ ```ê°œë³„ Base Modelì˜ ì„±ëŠ¥```ì´ ì¤‘ìš”í•¨ì„ ë³¸ íŠœí† ë¦¬ì–¼ì„ í†µí•´ ì‹¤í—˜ì ìœ¼ë¡œ ë‹¤ì‹œ í•œ ë²ˆ ë” ê¹¨ë‹¬ì„ ìˆ˜ ìˆì—ˆìŠµë‹ˆë‹¤. ë˜í•œ ë³¸ ì‹¤í—˜ì—ì„œëŠ” ì´ ë‘ ê°€ì§€ ìš”ì¸ìœ¼ë¡œ ì¸í•´ Baggingì˜ íš¨ê³¼ê°€ ì €ì¡°í–ˆë˜ ê²ƒì¸ì§€, ì•„ë‹ˆë©´ ```ëª¨ë¸ ë³µì¡ë„ê°€ ë‚®ì€ Base Model```ì„ ì‚¬ìš©í•´ ì´ëŸ¬í•œ ê²°ê³¼ê°€ ì•¼ê¸°ëœ ê²ƒì¸ì§€ ì •í™•í•œ ë¹„êµ ì‹¤í—˜ì„ ìˆ˜í–‰í•˜ì§€ ëª»í–ˆë‹¤ëŠ” ê²ƒì´ ì£¼ìš” í•œê³„ì ì…ë‹ˆë‹¤. 